{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract Collider Prompts\n",
    "\n",
    "This notebook first explains the datastructure used in (Rehder and Waldmann, 2017)\n",
    "and then demonstrates how to **construct the RW17 domain components** using helper functions \n",
    "from `dataset_creation`, and **convert them into a structured DataFrame**.\n",
    "\n",
    "We will:\n",
    "1. **Create a domain dictionary** using `create_domain_dict`\n",
    "2. **Expand it into a DataFrame** using `expand_domain_to_dataframe`\n",
    "3. **Add inference tasks** to extend the dataset\n",
    "4. **Generate verbalized prompts** for human evaluation\n",
    "\n",
    "\n",
    "This step will:\n",
    "\n",
    "Load and examine rw_17_domain_components (the predefined dataset components).\n",
    "Break down its structure to understand:\n",
    "Domain dictionary (specification of causal variables).\n",
    "Graph structure (causal relationships).\n",
    "Inference tasks (reasoning scenarios).\n",
    "Explain how these elements combine to generate prompts for LLMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creation module imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure Python finds the `src` directory\n",
    "sys.path.append(os.path.abspath(\"../../src\"))\n",
    "\n",
    "# Import everything defined in `__all__`\n",
    "from causalalign.dataset_creation import (\n",
    "    rw_17_domain_components,\n",
    "    graph_structures,\n",
    "    inference_tasks_rw17,\n",
    "    generate_prompt_dataframe,\n",
    "    expand_domain_to_dataframe,\n",
    "    expand_df_by_task_queries,\n",
    "    create_domain_dict,\n",
    "    verbalize_domain_intro,\n",
    "    verbalize_causal_mechanism,\n",
    "    verbalize_inference_task,\n",
    "    append_dfs,\n",
    ")\n",
    "\n",
    "print(\"Dataset creation module imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Understanding the RW17 Dataset Structure\n",
    "\n",
    "Before generating new datasets, we need to understand the structure of **RW17 domain components**.\n",
    "\n",
    "## üîπ What Is RW17?\n",
    "RW17 presented humans with causal inference tasks and asked for their likelihood judgements. Each causal inference task was presented on four subsequent screens.\n",
    "In the following, I will describe how I translated the experimental materials used by RW17 into nested dictionaries, which serve as the backbone to algorithmically  generate  the materials in RW17 in *textual form* such that we can prompt and compare LLMs' causal judgements. The following notebook explains how to algoritmically re-create the the textual form used by RW17 and also, how to easily create new prompts.\n",
    "\n",
    "RW17 used 3 different knowledge domains, in particular economy, sociology, and weather, in which the inference tasks were thematically embedded.\n",
    "Each domain specifies:\n",
    "- **Variables (`C1`, `C2`, `E`)**: The causal variables / graph nodes, e.g., C1: interest rates\n",
    "- **Variable Sense depending on binary values 0 or 1 for (`C1`, `C2`, `E`)**: e.g. for C1=1: *high* interest rates\n",
    "- ** Counterbalance-dependent Sense Assignments (`p/m`)**: How we represent conditions in counterbalanced ways (optional, but used in RW17). Essentially, this flips the senses of what it means for the variable to be on (1) or off (0).\n",
    "\n",
    "The verbalization of the prompt depends on the domain and:\n",
    "- **Causal Mechanisms**: How the variables influence each other (e.g., specified by collider, graph or chain graph)\n",
    "- **Inference Tasks**: The reasoning problems we ask an LLM to solve specified by \n",
    "\n",
    "By combining these components, we **generate structured natural language prompts** that can be used for causal reasoning tasks in an LLMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How Graph Structures Define Causal Mechanisms\n",
    "\n",
    "A **graph structure** specifies how causal variables (`C1`, `C2`, `E`) relate to each other.\n",
    "\n",
    "### Example Graph Structures:\n",
    "1. **Collider** (`C1 ‚Üí E ‚Üê C2`)\n",
    "   - `C1` and `C2` both cause `E`.\n",
    "\n",
    "2. **Fork** (`C1 ‚Üê E ‚Üí C2`)\n",
    "   - `E` causes both `C1` and `C2`.\n",
    "\n",
    "3. **Chain** (`C1 ‚Üí C2 ‚Üí E`)\n",
    "   - `C1` causes `C2`, which then affects `E`.\n",
    "\n",
    "Let's look at the graph structures dictionary that is already pre-defined in ``src/causalalign/dataset_creation/constants.py``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chain': {'causal_template': '{c1_sense} {c1_name} causes {c2_sense} '\n",
      "                              '{c2_name}. And {c2_sense} {c2_name} causes '\n",
      "                              '{e_sense} {e_name}.',\n",
      "           'description': 'C1‚ÜíC2‚ÜíE'},\n",
      " 'collider': {'causal_template': '{c1_sense} {c1_name} causes {e_sense} '\n",
      "                                 '{e_name}. Also, {c2_sense} {c2_name} causes '\n",
      "                                 '{e_sense} {e_name}.',\n",
      "              'description': 'C1‚ÜíE‚ÜêC2'},\n",
      " 'fork': {'causal_template': '{c1_sense} {c1_name} causes {e_sense} {e_name}. '\n",
      "                             'Also, {c1_sense} {c1_name} causes {c2_sense} '\n",
      "                             '{c2_name}.',\n",
      "          'description': 'E‚ÜêC1‚ÜíC2'}}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-print available graph structures\n",
    "pprint.pprint(graph_structures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How Inference Tasks Define the Final Prompt\n",
    "\n",
    "Inference tasks specify **what the LLM needs to predict** given certain observations.\n",
    "\n",
    "For example:\n",
    "- `\"a\": {\"query_node\": \"Ci\", \"observation\": \"Cj=1\", \"query\": \"Ci=?\"}`\n",
    "  - **Ask:** Given that `Cj=1`, what is the likely value of `Ci`?\n",
    "  - This corresponds to **a causal reasoning question**.\n",
    "\n",
    "Inference tasks work together with **domain dictionaries** and **graph structures** to create **verbalized prompts**.\n",
    "\n",
    "### üîó How It All Connects:\n",
    "1. **Domain Dictionary** ‚Üí Specifies **variables and values**.\n",
    "2. **Graph Structure** ‚Üí Defines **causal relationships**.\n",
    "3. **Inference Tasks** ‚Üí Frame **the reasoning problem**.\n",
    "4. **Prompt Verbalization** ‚Üí Converts this into **natural language for LLMs**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'observation': 'E=1, Cj=1',\n",
      "       'query': 'p(Ci=1|E=1, Cj=1)',\n",
      "       'query_node': 'Ci=1'},\n",
      " 'b': {'observation': 'E=1', 'query': 'p(Ci=1|E=1)', 'query_node': 'Ci=1'},\n",
      " 'c': {'observation': 'E=1, Cj=0',\n",
      "       'query': 'p(Ci=1|E=1, Cj=0)',\n",
      "       'query_node': 'Ci=1'},\n",
      " 'd': {'observation': 'Cj=1', 'query': 'p(Ci=1|Cj=1)', 'query_node': 'Ci=1'},\n",
      " 'e': {'observation': 'Cj=0', 'query': 'p(Ci=1|Cj=0)', 'query_node': 'Ci=1'},\n",
      " 'f': {'observation': 'E=0, Cj=1',\n",
      "       'query': 'p(Ci=1|E=0, Cj=1)',\n",
      "       'query_node': 'Ci=1'},\n",
      " 'g': {'observation': 'E=0', 'query': 'p(Ci=1|E=0)', 'query_node': 'Ci=1'},\n",
      " 'h': {'observation': 'E=0, Cj=0',\n",
      "       'query': 'p(Ci=1|E=0, Cj=0)',\n",
      "       'query_node': 'Ci=1'},\n",
      " 'i': {'observation': 'Ci=0, Cj=0',\n",
      "       'query': 'p(E=1|Ci=0, Cj=0)',\n",
      "       'query_node': 'E=1'},\n",
      " 'j': {'observation': 'Ci=0, Cj=1',\n",
      "       'query': 'p(E=1|Ci=0, Cj=1)',\n",
      "       'query_node': 'E=1'},\n",
      " 'k': {'observation': 'Ci=1, Cj=1',\n",
      "       'query': 'p(E=1|Ci=1, Cj=1)',\n",
      "       'query_node': 'E=1'}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(inference_tasks_rw17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain_name': 'sociology',\n",
       " 'variables': {'C1': {'C1_name': 'urbanization',\n",
       "   'C1_detailed': 'Urbanization is the degree to which the members of a society live in urban environments (i.e., cities) versus rural environments.',\n",
       "   'p_value': {'1': 'high', '0': 'normal'},\n",
       "   'm_value': {'1': 'low', '0': 'normal'},\n",
       "   'explanations': {'p_p': 'Big cities provide many opportunities for financial and social improvement.',\n",
       "    'p_m': 'In big cities many people are competing for the same high-status jobs and occupations.',\n",
       "    'm_p': 'People in rural areas are rarely career oriented, and so take time off from working and switch frequently between different \"temp\" jobs.',\n",
       "    'm_m': 'The low density of people prevents the dynamic economic expansion needed for people to get ahead.'}},\n",
       "  'C2': {'C2_name': 'interest in religion',\n",
       "   'C2_detailed': 'Interest in religion is the degree to which the members of a society show a curiosity in religion issues or participate in organized religions.',\n",
       "   'p_value': {'1': 'low', '0': 'normal'},\n",
       "   'm_value': {'1': 'high', '0': 'normal'},\n",
       "   'explanations': {'p_p': 'Without the restraint of religion-based morality, the impulse toward greed dominates and people tend to accumulate material wealth.',\n",
       "    'p_m': 'Many religions reinforce a strong work ethic; without this motivation, workers become complacent at their jobs.',\n",
       "    'm_p': 'Religion fosters communal care, and those of the same religion tend to support each other with jobs, financial favors, and so on.',\n",
       "    'm_m': 'The spiritualism induced by religion works to reduce the desire for material wealth.'}},\n",
       "  'E': {'E_name': 'socio-economic mobility',\n",
       "   'E_detailed': 'Socioeconomic mobility is the degree to which the members of a society are able to improve their social and economic status.',\n",
       "   'p_value': {'1': 'high', '0': 'normal'},\n",
       "   'm_value': {'1': 'low', '0': 'normal'}}},\n",
       " 'introduction': 'Sociologists seek to describe and predict the regular patterns of societal interactions. To do this, they study some important variables or attributes of societies. They also study how these attributes are responsible for producing or causing one another.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scocio_dict_const = rw_17_domain_components[\"sociology\"]\n",
    "scocio_dict_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_df_test_socio = generate_prompt_dataframe(\n",
    "    domain_dict=scocio_dict_const,\n",
    "    inference_tasks=inference_tasks_rw17,\n",
    "    graph_type=\"collider\",\n",
    "    graph_structures=graph_structures,\n",
    "    counterbalance_enabled=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore how these components are combined by re-creating the prompts used in RW17 starting with re-creating the dictionaries that are stored in ``constants.py``!\n",
    "\n",
    "\n",
    "# Step 1: Create Domain Dictionray:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create individual domains\n",
    "# economy_domain_dict = create_domain_dict(\n",
    "#     domain=\"economy\",\n",
    "#     introduction=\"Economists seek to describe and predict the regular patterns of economic fluctuation. To do this, they study some important variables or attributes of economies. They also study how these attributes are responsible for producing or causing one another.\",\n",
    "#     C1_name=\"interest rates\",\n",
    "#     C1_detailed=\"Interest rates are the rates banks charge to loan money.\",\n",
    "#     C1_values={\"1\": \"low\", \"0\": \"high\"},\n",
    "#     C2_name=\"trade deficits\",\n",
    "#     C2_detailed=\"A country's trade deficit is the difference between the value of the goods that a country imports and the value of the goods that a country exports.\",\n",
    "#     C2_values={\"1\": \"small\", \"0\": \"large\"},\n",
    "#     E_name=\"retirement savings\",\n",
    "#     E_detailed=\"Retirement savings is the money people save for their retirement.\",\n",
    "#     E_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "#     counterbalance_enabled=True,\n",
    "# )\n",
    "\n",
    "# sociology_domain_dict = create_domain_dict(\n",
    "#     domain=\"sociology\",\n",
    "#     introduction=\"Sociologists seek to describe and predict the regular patterns of societal interactions. To do this, they study some important variables or attributes of societies. They also study how these attributes are responsible for producing or causing one another.\",\n",
    "#     C1_name=\"urbanization\",\n",
    "#     C1_detailed=\"Urbanization is the degree to which the members of a society live in urban environments (i.e., cities) versus rural environments.\",\n",
    "#     C1_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "#     C2_name=\"interest in religion\",\n",
    "#     C2_detailed=\"Interest in religion is the degree to which the members of a society show a curiosity in religion issues or participate in organized religions.\",\n",
    "#     C2_values={\"1\": \"low\", \"0\": \"high\"},\n",
    "#     E_name=\"socio-economic mobility\",\n",
    "#     E_detailed=\"Socioeconomic mobility is the degree to which the members of a society are able to improve their social and economic status.\",\n",
    "#     E_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "#     counterbalance_enabled=True,\n",
    "# )\n",
    "\n",
    "# weather_domain_dict = create_domain_dict(\n",
    "#     domain=\"weather\",\n",
    "#     introduction=\"Meteorologists seek to describe and predict the regular patterns that govern weather systems. To do this, they study some important variables or attributes of weather systems. They also study how these attributes are responsible for producing or causing one another.\",\n",
    "#     C1_name=\"ozone levels\",\n",
    "#     C1_detailed=\"Ozone is a gaseous allotrope of oxygen (O3) and is formed by exposure to UV radiation.\",\n",
    "#     C1_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "#     C2_name=\"air pressure\",\n",
    "#     C2_detailed=\"Air pressure is force exerted due to concentrations of air molecules.\",\n",
    "#     C2_values={\"1\": \"low\", \"0\": \"high\"},\n",
    "#     E_name=\"humidity\",\n",
    "#     E_detailed=\"Humidity is the degree to which the atmosphere contains water molecules.\",\n",
    "#     E_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "#     counterbalance_enabled=True,\n",
    "# )\n",
    "\n",
    "\n",
    "abc_domain_dict = create_domain_dict(\n",
    "    domain=\"abc\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"A\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "    C2_name=\"B\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"small\", \"0\": \"large\"},\n",
    "    E_name=\"C\",\n",
    "    E_detailed=\"\",\n",
    "    E_values={\"1\": \"long\", \"0\": \"short\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "xyz_domain_dict = create_domain_dict(\n",
    "    domain=\"xyz\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"X\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "    C2_name=\"Y\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"small\", \"0\": \"large\"},\n",
    "    E_name=\"Z\",\n",
    "    E_detailed=\"\",\n",
    "    E_values={\"1\": \"long\", \"0\": \"short\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "# D, Y, X ‚Üí In causal inference, where D is the treatment, Y is the outcome, and X represents covariates.\n",
    "dyx_domain_dict = create_domain_dict(\n",
    "    domain=\"dyx\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"D\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"strong\", \"0\": \"weak\"},\n",
    "    C2_name=\"X\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"low\", \"0\": \"high\"},\n",
    "    E_name=\"Y\",\n",
    "    E_detailed=\"\",\n",
    "    E_values={\"1\": \"long\", \"0\": \"short\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "\n",
    "# q1, q2, q3 ‚Üí Used in dynamical systems or quantum mechanics.\n",
    "q123_domain_dict = create_domain_dict(\n",
    "    domain=\"q123\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"q1\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"high-energy\", \"0\": \"low-engergy\"},\n",
    "    C2_name=\"q2\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"prolonged\", \"0\": \"shortened\"},\n",
    "    E_name=\"q3\",\n",
    "    E_detailed=\"\",\n",
    "    E_values={\"1\": \"extended\", \"0\": \"short\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "dyx_medicine_domain_dict = create_domain_dict(\n",
    "    domain=\"dyx_medicine\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"D\",\n",
    "    C1_detailed=\"\",  # Represents the treatment level or dosage: e.g. Dose of a drug\n",
    "    C1_values={\n",
    "        \"1\": \"high\",\n",
    "        \"0\": \"low\",\n",
    "    },  # or {\"1\": \"intensive\", \"0\": \"mild\"} for therapy\n",
    "    C2_name=\"X\",\n",
    "    C2_detailed=\"\",  # Represents patient-related covariates that may affect the outcome. e.g. risk\n",
    "    C2_values={\n",
    "        \"1\": \"high\",\n",
    "        \"0\": \"low\",\n",
    "    },  # or {\"1\": \"young\", \"0\": \"elderly\"} if age is the covariate\n",
    "    E_name=\"Y\",\n",
    "    E_detailed=\"\",  # Represents the observed health outcome., e.g. duration of recovery\n",
    "    E_values={\n",
    "        \"1\": \"long\",\n",
    "        \"0\": \"short\",\n",
    "    },  # or {\"1\": \"severe\", \"0\": \"mild\"} for disease severity\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "dyx_economics_domain_dict = create_domain_dict(\n",
    "    domain=\"dyx_economics\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"D\",\n",
    "    C1_detailed=\"\",  # Represents the strength of an economic policy or intervention: e.g. Tax policy strength\n",
    "    C1_values={\n",
    "        \"1\": \"strong\",\n",
    "        \"0\": \"weak\",\n",
    "    },  # or {\"1\": \"high\", \"0\": \"low\"} for subsidies\n",
    "    C2_name=\"X\",\n",
    "    C2_detailed=\"\",  # Represents economic conditions that may influence the policy's effectiveness: e.g. market stability\n",
    "    C2_values={\n",
    "        \"1\": \"unstable\",\n",
    "        \"0\": \"stable\",\n",
    "    },  # or {\"1\": \"low\", \"0\": \"high\"} for income level\n",
    "    E_name=\"Y\",\n",
    "    E_detailed=\"\",  # Represents the observed economic impact of the policy: e.g. economic growth\n",
    "    E_values={\n",
    "        \"1\": \"high\",\n",
    "        \"0\": \"low\",\n",
    "    },  # or {\"1\": \"long\", \"0\": \"short\"} for unemployment duration\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "xyz_psychology_domain_dict = create_domain_dict(\n",
    "    domain=\"xyz_psychology\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"X\",\n",
    "    C1_detailed=\"\",  # Represents the intensity of the intervention or stimulus exposure: e.g. stress level\n",
    "    C1_values={\n",
    "        \"1\": \"high\",\n",
    "        \"0\": \"low\",\n",
    "    },  # or {\"1\": \"intense\", \"0\": \"mild\"} for cognitive training\n",
    "    C2_name=\"Y\",\n",
    "    C2_detailed=\"\",  # Represents individual differences that may influence response to the intervention: e.g. anxiety level\n",
    "    C2_values={\n",
    "        \"1\": \"high\",\n",
    "        \"0\": \"low\",\n",
    "    },  # or {\"1\": \"experienced\", \"0\": \"novice\"} for prior knowledge\n",
    "    E_name=\"Z\",\n",
    "    E_detailed=\"\",  # Represents the measured cognitive or behavioral outcome: e.g. reaction time\n",
    "    E_values={\n",
    "        \"1\": \"slow\",\n",
    "        \"0\": \"fast\",\n",
    "    },  # or {\"1\": \"high\", \"0\": \"low\"} for learning retention\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "# uncommon single letters\n",
    "gft_domain_dict = create_domain_dict(\n",
    "    domain=\"gft\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"G\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "    C2_name=\"F\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"small\", \"0\": \"large\"},\n",
    "    E_name=\"T\",\n",
    "    E_detailed=\"\",\n",
    "    E_values={\"1\": \"long\", \"0\": \"short\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "\n",
    "abstract_domain_dict = create_domain_dict(\n",
    "    domain=\"xqt\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"fwp\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "    C2_name=\"blg\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"small\", \"0\": \"large\"},\n",
    "    E_name=\"drk\",\n",
    "    E_detailed=\"\",\n",
    "    E_values={\"1\": \"large\", \"0\": \"small\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n",
    "\n",
    "\n",
    "very_abstract_domain_dict = create_domain_dict(\n",
    "    domain=\"zorpentix\",\n",
    "    introduction=\"In the following, you will be presented with causal inference tasks based on a causal mechanism consisting of 3 variables that works like this:\",\n",
    "    C1_name=\"flarnox\",\n",
    "    C1_detailed=\"\",\n",
    "    C1_values={\"1\": \"present\", \"0\": \"absent\"},\n",
    "    C2_name=\"drimbex\",\n",
    "    C2_detailed=\"\",\n",
    "    C2_values={\"1\": \"present\", \"0\": \"absent\"},\n",
    "    E_name=\"quorvex\",\n",
    "    E_detailed=\".\",\n",
    "    E_values={\"1\": \"high\", \"0\": \"low\"},\n",
    "    counterbalance_enabled=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should re-create our rw17 dictionary. Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain_name': 'abc',\n",
      " 'introduction': 'In the following, you will be presented with causal '\n",
      "                 'inference tasks based on a causal mechanism consisting of 3 '\n",
      "                 'variables that works like this:',\n",
      " 'variables': {'C1': {'C1_detailed': '',\n",
      "                      'C1_name': 'A',\n",
      "                      'm_value': {'0': 'high', '1': 'low'},\n",
      "                      'p_value': {'0': 'low', '1': 'high'}},\n",
      "               'C2': {'C2_detailed': '',\n",
      "                      'C2_name': 'B',\n",
      "                      'm_value': {'0': 'small', '1': 'large'},\n",
      "                      'p_value': {'0': 'large', '1': 'small'}},\n",
      "               'E': {'E_detailed': '',\n",
      "                     'E_name': 'C',\n",
      "                     'm_value': {'0': 'long', '1': 'short'},\n",
      "                     'p_value': {'0': 'short', '1': 'long'}}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(abc_domain_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Expand the Dictionaries into Prompt Components in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for each domain and then append them together\n",
    "\n",
    "abc_df = expand_domain_to_dataframe(\n",
    "    abc_domain_dict,\n",
    ")\n",
    "xyz_domain_df = expand_domain_to_dataframe(\n",
    "    xyz_domain_dict,\n",
    ")\n",
    "abstract_domain_df = expand_domain_to_dataframe(\n",
    "    abstract_domain_dict,\n",
    ")\n",
    "very_abstract_df = expand_domain_to_dataframe(\n",
    "    very_abstract_domain_dict,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each domain dataframe now has 8 rows  \n",
      " and the following columns: \n",
      " Index(['domain', 'C1', 'C1_values', 'C1_cntbl', 'C1_sense', 'C1_detailed',\n",
      "       'C2', 'C2_values', 'C2_cntbl', 'C2_sense', 'C2_detailed', 'E',\n",
      "       'E_values', 'E_cntbl', 'E_sense', 'E_detailed', 'cntbl_cond'],\n",
      "      dtype='object').\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>C1</th>\n",
       "      <th>C1_values</th>\n",
       "      <th>C1_cntbl</th>\n",
       "      <th>C1_sense</th>\n",
       "      <th>C1_detailed</th>\n",
       "      <th>C2</th>\n",
       "      <th>C2_values</th>\n",
       "      <th>C2_cntbl</th>\n",
       "      <th>C2_sense</th>\n",
       "      <th>C2_detailed</th>\n",
       "      <th>E</th>\n",
       "      <th>E_values</th>\n",
       "      <th>E_cntbl</th>\n",
       "      <th>E_sense</th>\n",
       "      <th>E_detailed</th>\n",
       "      <th>cntbl_cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>high</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>small</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td>ppp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>high</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>small</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>short</td>\n",
       "      <td></td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>high</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>large</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td>pmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>high</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>large</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>short</td>\n",
       "      <td></td>\n",
       "      <td>pmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>low</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>small</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td>mpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>low</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>small</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>short</td>\n",
       "      <td></td>\n",
       "      <td>mpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>low</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>large</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td>mmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abc</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>low</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>large</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>short</td>\n",
       "      <td></td>\n",
       "      <td>mmm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  domain C1 C1_values C1_cntbl C1_sense C1_detailed C2 C2_values C2_cntbl  \\\n",
       "0    abc  A         1        p     high              B         1        p   \n",
       "1    abc  A         1        p     high              B         1        p   \n",
       "2    abc  A         1        p     high              B         1        m   \n",
       "3    abc  A         1        p     high              B         1        m   \n",
       "4    abc  A         1        m      low              B         1        p   \n",
       "5    abc  A         1        m      low              B         1        p   \n",
       "6    abc  A         1        m      low              B         1        m   \n",
       "7    abc  A         1        m      low              B         1        m   \n",
       "\n",
       "  C2_sense C2_detailed  E E_values E_cntbl E_sense E_detailed cntbl_cond  \n",
       "0    small              C        1       p    long                   ppp  \n",
       "1    small              C        1       m   short                   ppm  \n",
       "2    large              C        1       p    long                   pmp  \n",
       "3    large              C        1       m   short                   pmm  \n",
       "4    small              C        1       p    long                   mpp  \n",
       "5    small              C        1       m   short                   mpm  \n",
       "6    large              C        1       p    long                   mmp  \n",
       "7    large              C        1       m   short                   mmm  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"Each domain dataframe now has {len(abc_df)} rows  \\n and the following columns: \\n {abc_df.columns}.\"\n",
    ")\n",
    "abc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the entire prompt for each condition and domain:\n",
    "\n",
    "- Step 1:  for each domain dictionary, create the domain dataframe and then the verbalizations\n",
    "- Step 2: append all complete dataframes\n",
    "- Step 3: _optionally_ subset for counterbalance conditions of interest\n",
    "- Step 4: _optionally_ merge with human data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Response prompt instructions:\n",
    "\n",
    "\n",
    "Please provide your response in the following strict XML format without any additional text or explanation:\n",
    "```\n",
    "<response>\n",
    "    <likelihood>YOUR_NUMERIC_RESPONSE_HERE</likelihood>\n",
    "    <confidence>YOUR_CONFIDENCE_SCORE_HERE</confidence>\n",
    "</response>\n",
    "\n",
    "```\n",
    "\n",
    "Only replace YOUR_NUMERIC_RESPONSE_HERE with a number between 0 (unlikely) and 100 (very likely), and YOUR_CONFIDENCE_SCORE_HERE with a number between 0 (very uncertain) and 100 (very certain). Do not include any explanations or text outside the XML format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_format_numeric_certainty = \"<response><likelihood>YOUR_NUMERIC_RESPONSE_HERE</likelihood><confidence>YOUR_CONFIDENCE_SCORE_HERE</confidence></response>\"\n",
    "xml_explanation_numeric_certainty = \"Only replace YOUR_NUMERIC_RESPONSE_HERE with a number between 0 (unlikely) and 100 (very likely), and YOUR_CONFIDENCE_SCORE_HERE with a number between 0 (very uncertain) and 100 (very certain). DO NOT include any other information or text in your response and DO NOT use any special characters or symbols like quotation marks around your text output. Only return the XML inline as raw text\"\n",
    "prompt_type_xml_numeric_certainty = (\n",
    "    \"Return your response as raw text in one single line using this exact XML format: \"\n",
    "    + xml_format_numeric_certainty\n",
    "    + \" \"\n",
    "    + \"DO NOT use Markdown, code blocks, or any additional formatting.\"\n",
    "    # \"Return your response in a single line, without line breaks within the following XML format. Do NOT use Markdown, code blocks, or any additional formatting. DO NOT add quotation marks around the response. DO NOT provide any additional information. Output must be in the exact XML format below, inline \"\n",
    "    # \"Please provide your response in the following strict XML format. Provide your response in a single line. DO NOT provide any additional information outside the  formatting like line breaks and ensure the XML is returned as raw text without any code markers e.g., ```xml or quotation marks: \"\n",
    "    # + xml_format_numeric_certainty\n",
    "    + \" \"\n",
    "    + xml_explanation_numeric_certainty\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, we'll call `generate_prompt_dataframe()` for each domain dictionary. \n",
    "We'll start with one domain dictionary and after that, we'll loop over the remaining domain dictionaries\n",
    "and append the resulting dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to append the domain dataframes to\n",
    "abstract_complete_df = generate_prompt_dataframe(\n",
    "    domain_dict=abc_domain_dict,\n",
    "    inference_tasks=inference_tasks_rw17,\n",
    "    graph_type=\"collider\",\n",
    "    graph_structures=graph_structures,\n",
    "    counterbalance_enabled=True,\n",
    "    prompt_category=\"numeric-certainty\",\n",
    "    prompt_type=prompt_type_xml_numeric_certainty,\n",
    ")\n",
    "\n",
    "# list of remaining domain dictionaries\n",
    "domain_dicts_xs = [\n",
    "    q123_domain_dict,\n",
    "    dyx_economics_domain_dict,\n",
    "    xyz_psychology_domain_dict,\n",
    "    dyx_medicine_domain_dict,\n",
    "    dyx_domain_dict,\n",
    "    xyz_domain_dict,\n",
    "    gft_domain_dict,\n",
    "    abstract_domain_dict,\n",
    "    very_abstract_domain_dict,\n",
    "]\n",
    "\n",
    "\n",
    "# we'll start with the completed economy dataframe and append the other domain dataframes to it\n",
    "new_over_complete_df = (\n",
    "    abstract_complete_df.copy()  # over complete means, it has all 8 possible counterbalance conditions.\n",
    "    # we'll subset later for the 4 counterbalance conditions that were used\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now loop over remaining domain dicts and append them to the one created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over remaining domain dictionaries and append the\n",
    "# resulting dataframes to the first dataframe created in the cell above\n",
    "\n",
    "for dict in domain_dicts_xs:\n",
    "    # for dict in rw_17_domain_components.values():\n",
    "    df = generate_prompt_dataframe(\n",
    "        domain_dict=dict,\n",
    "        inference_tasks=inference_tasks_rw17,\n",
    "        graph_type=\"collider\",\n",
    "        graph_structures=graph_structures,\n",
    "        counterbalance_enabled=True,\n",
    "        prompt_category=\"numeric-certainty\",\n",
    "        prompt_type=prompt_type_xml_numeric_certainty,\n",
    "    )\n",
    "    # append the new dataframe to the complete dataframe\n",
    "    new_over_complete_df = append_dfs(new_over_complete_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ppp', 'ppm', 'pmp', 'pmm', 'mpp', 'mpm', 'mmp', 'mmm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_complete_df[\"cntbl_cond\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ppp', 'ppm', 'pmp', 'pmm', 'mpp', 'mpm', 'mmp', 'mmm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_over_complete_df[\"cntbl_cond\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting for the Counterbalance conditions used in RW17\n",
    "- and adding unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a unique id to each row\n",
    "new_over_complete_df[\"id\"] = range(1, len(new_over_complete_df) + 1)\n",
    "\n",
    "# subset for the counterbalance conditions used in the RW17 study\n",
    "# select_contbl_cond_xs = [\"ppp\", \"pmm\", \"mmp\", \"mpm\"]\n",
    "select_contbl_cond_xs = [\"ppp\", \"pmm\", \"mmp\", \"mpm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_complete_df = new_over_complete_df[\n",
    "    new_over_complete_df[\"cntbl_cond\"].isin(select_contbl_cond_xs)\n",
    "]\n",
    "\n",
    "# save new_complete_df to a csv file#\n",
    "prompt_category = new_complete_df[\"prompt_category\"].unique()[0]\n",
    "graph_type = new_complete_df[\"graph\"].unique()[0]\n",
    "new_complete_df.to_csv(\n",
    "    f\"../datasets/abstract_collider_prompts/abc_abstract_{prompt_category}_LLM_prompting_{graph_type}_abstract.csv\",\n",
    "    index=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "Index(['domain', 'C1', 'C1_values', 'C1_cntbl', 'C1_sense', 'C1_detailed',\n",
      "       'C2', 'C2_values', 'C2_cntbl', 'C2_sense', 'C2_detailed', 'E',\n",
      "       'E_values', 'E_cntbl', 'E_sense', 'E_detailed', 'cntbl_cond', 'task',\n",
      "       'query_node', 'observation', 'query', 'graph', 'prompt',\n",
      "       'prompt_category', 'id'],\n",
      "      dtype='object')\n",
      "['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k']\n",
      "['abc' 'q123' 'dyx_economics' 'xyz_psychology' 'dyx_medicine' 'dyx' 'xyz'\n",
      " 'gft' 'xqt' 'zorpentix']\n"
     ]
    }
   ],
   "source": [
    "print(len(new_complete_df))\n",
    "print(new_complete_df.columns)\n",
    "print(new_complete_df[\"task\"].unique())\n",
    "print(new_complete_df[\"domain\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dataframes to csv\n",
    "\n",
    "### To prompt the the LLMs, we only need the id and prompt.\n",
    "- to not confuse the LLMs, we should group them by counterbalance condition when interacting with them through the website.\n",
    "- however, the default when interacting with them throught their respective APIs is that they're stateless, meaning they don't retain anything from the previous context.\n",
    "    - this is why we don't have to worry about having the different counterbalance conditions contradict each other and hence confuse the LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric-certainty collider\n",
      "Prompts for LLMs saved successfully!\n",
      "prompt data file has the following columns:\n",
      "Index(['id', 'prompt', 'prompt_category', 'graph', 'domain', 'cntbl_cond',\n",
      "       'task'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# save for prompting LLMs\n",
    "LLM_prompting_df = new_complete_df[\n",
    "    [\"id\", \"prompt\", \"prompt_category\", \"graph\", \"domain\", \"cntbl_cond\", \"task\"]\n",
    "]\n",
    "prompt_category = LLM_prompting_df[\"prompt_category\"].unique()[0]\n",
    "graph_type = LLM_prompting_df[\"graph\"].unique()[0]\n",
    "print(prompt_category, graph_type)\n",
    "LLM_prompting_df.head(\n",
    "    11\n",
    ").to_csv(  ## NOTE: only saving the first 11 rows for now, to check the output. DELETE THIS LINE LATER\n",
    "    f\"../datasets/abstract_collider_prompts/prompts_for_LLM_api/abc_{prompt_category}_LLM_prompting_{graph_type}_abstract.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "print(\"Prompts for LLMs saved successfully!\")\n",
    "print(\"prompt data file has the following columns:\")\n",
    "print(LLM_prompting_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-causality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
